{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment seed\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from contextlib import redirect_stdout\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "    '''\n",
    "    Sets all necessary seed for reproduceability.\n",
    "    '''\n",
    "    os.environ['PYTHONHASHSEED']=str(1)\n",
    "    tf.random.set_seed(1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset and perform stratified train test split\n",
    "\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], \n",
    "                                                    test_size=0.2, random_state=0, \n",
    "                                                    stratify=data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyper-parameters. \n",
    "\n",
    "hyper_params = {\n",
    "    'VOCAB_SIZE':50000,\n",
    "    'BS':512,\n",
    "    'LR':0.01,\n",
    "    'OOV_TOK':\"<OOV>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using the training dataset. Subsequently apply is on the train and test dataset.\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=hyper_params['OOV_TOK'])\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set more hyper-parameters\n",
    "\n",
    "hyper_params['MAX_LENGTH'] = 520\n",
    "hyper_params['PADDING_TYPE'] = \"post\"\n",
    "hyper_params['TRUNC_TYPE'] = \"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform padding on training and testing dataset using our hyper-parameters set.\n",
    "\n",
    "training_padded = pad_sequences(train_sequences, padding=hyper_params['PADDING_TYPE'], \n",
    "                                maxlen=hyper_params['MAX_LENGTH'], truncating=hyper_params['TRUNC_TYPE'])\n",
    "testing_padded = pad_sequences(test_sequences, padding=hyper_params['PADDING_TYPE'], \n",
    "                               maxlen=hyper_params['MAX_LENGTH'], truncating=hyper_params['TRUNC_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categeorical labels into integers and store in a numpy array\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "for item in y_train:\n",
    "    if item == 'positive':\n",
    "        train_labels.append(1)\n",
    "    else:\n",
    "        train_labels.append(0)\n",
    "        \n",
    "for item in y_test:\n",
    "    if item == 'positive':\n",
    "        test_labels.append(1)\n",
    "    else:\n",
    "        test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels).astype('float32')\n",
    "test_labels = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ae custom call back to record the time taken per epoch.\n",
    "\n",
    "class timelogCallback(keras.callbacks.Callback):\n",
    "    '''\n",
    "    Inherits callbacks.Callback from keras. Records\n",
    "    the time taken from start to end of each epoch.\n",
    "    '''\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.timelog = []\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.start_time = time.time()\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.timelog.append(time.time() - self.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>GRU-1 Grid Search Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to be used during our Grid Search. The patience values were\n",
    "# decided based on the Vanilla 1-Layer GRU trained\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00005, verbose=1)\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "timelog = timelogCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a 1-Layer GRU model with tuneable hyper-parameters\n",
    "# Returns a compiled model.\n",
    "\n",
    "def create_GRU1(em_dims, units):\n",
    "    GRU1_model = keras.Sequential([\n",
    "        keras.layers.Embedding(len(word_index)+1, em_dims, input_length=520),\n",
    "        keras.layers.GRU(units),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    GRU1_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hyper_params['LR']),\n",
    "                     loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return GRU1_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for grid search\n",
    "\n",
    "em_dims = [128, 256]\n",
    "unit1 = [100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform grid search and store the results in a dictionary for use later\n",
    "\n",
    "GRU1_history_dict = {}\n",
    "\n",
    "for em_dim in em_dims:\n",
    "    for u1 in unit1:\n",
    "        print(f\"Training with embedding dimensions: {em_dim}, unit1: {u1}\")\n",
    "        model = create_GRU1(em_dim, u1)\n",
    "        history = model.fit(training_padded, train_labels, batch_size = hyper_params['BS'],\n",
    "                            epochs=250, validation_data=(testing_padded, test_labels),\n",
    "                           callbacks=[reduce_lr, earlystop, timelog])\n",
    "        GRU1_history_dict[f'GRU1_history_{em_dim}_{u1}'] = history, timelog.timelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history and timelog of each model from the dictionary created in the cell above into a csv file\n",
    "\n",
    "for title, item in GRU1_history_dict.items():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(item[0].history)\n",
    "    time_df = pd.DataFrame(item[1])\n",
    "\n",
    "    # save to csv:\n",
    "    hist_csv_file = 'History_' + str(title) + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    time_csv_file = 'Time_' + str(title) + '.csv'\n",
    "    with open(time_csv_file, mode='w') as f:\n",
    "        time_df.to_csv(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss figure for the history of each model trained during grid search. Save it as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in GRU1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['loss'], name=str(key)+'Training Loss'))\n",
    "for key, item in GRU1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_loss'], name=str(key)+'Val Loss'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('GRU1_Gridsearch_Loss.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save accuracy figure for the history of each model trained during grid search. Save as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in GRU1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['accuracy'], name=str(key)+'Training Accuracy'))\n",
    "for key, item in GRU1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_accuracy'], name=str(key)+'Val Accuracy'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('GRU1_Gridsearch_Accuracy.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy of the grid searched models. Validation Accuracy is determined by the \n",
    "# last epoch of training\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key, item in GRU1_history_dict.items():\n",
    "    x.append(str(key)+'Val Accuracy')\n",
    "    y.append(item[0].history['val_accuracy'][-1])\n",
    "\n",
    "fig.add_trace(go.Bar(x=x, y=y))\n",
    "\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('GRU1_Barplot_Val_Acc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>GRU-2 Grid Search Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to be used during our Grid Search. The patience values were\n",
    "# decided based on the Vanilla 2-Layer GRU trained\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=4, min_lr=0.00005, verbose=1)\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12)\n",
    "timelog = timelogCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a 2-Layer GRU model with tuneable hyper-parameters\n",
    "# Returns a compiled model.\n",
    "\n",
    "def create_GRU2(em_dims, unit1, unit2):\n",
    "    GRU2_model = keras.Sequential([\n",
    "        keras.layers.Embedding(len(word_index)+1, em_dims, input_length=520),\n",
    "        keras.layers.GRU(unit1, return_sequences=True),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.GRU(unit2),\n",
    "        keras.layers.Dropout(0.5),    \n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    GRU2_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hyper_params['LR']),\n",
    "                     loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return GRU2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for grid search\n",
    "\n",
    "em_dims = [128, 256]\n",
    "unit1 = [100, 200]\n",
    "unit2 = [100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform grid search and store the results in a dictionary for use later\n",
    "\n",
    "GRU2_history_dict = {}\n",
    "\n",
    "for em_dim in em_dims:\n",
    "    for u1 in unit1:\n",
    "        for u2 in unit2:\n",
    "            print(f\"Training with em_dim:{em_dim}, unit1:{u1}, unit2:{u2}\")\n",
    "            model = create_GRU2(em_dim, u1, u2)\n",
    "            history = model.fit(training_padded, train_labels, batch_size = hyper_params['BS'],\n",
    "                                epochs=250, validation_data=(testing_padded, test_labels),\n",
    "                               callbacks=[reduce_lr, earlystop, timelog])\n",
    "            GRU2_history_dict[f'GRU2_history_{em_dim}_{u1}_{u2}'] = history, timelog.timelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history and timelog of each model from the dictionary created in the cell above into a csv file\n",
    "\n",
    "for title, item in GRU2_history_dict.items():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(item[0].history)\n",
    "    time_df = pd.DataFrame(item[1])\n",
    "\n",
    "    # save to csv:\n",
    "    hist_csv_file = 'History_' + str(title) + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    time_csv_file = 'Time_' + str(title) + '.csv'\n",
    "    with open(time_csv_file, mode='w') as f:\n",
    "        time_df.to_csv(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss figure for the history of each model trained during grid search. Save it as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in GRU2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['loss'], name=str(key)+'Training Loss'))\n",
    "for key, item in GRU2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_loss'], name=str(key)+'Val Loss'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('GRU2_Gridsearch_Loss.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save accuracy figure for the history of each model trained during grid search. Save as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in GRU2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['accuracy'], name=str(key)+'Training Accuracy'))\n",
    "for key, item in GRU2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_accuracy'], name=str(key)+'Val Accuracy'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('GRU2_Gridsearch_Accuracy.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the validation accuracy of the grid searched models. Validation Accuracy is determined by the \n",
    "# last epoch of training\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key, item in GRU2_history_dict.items():\n",
    "    x.append(str(key)+'Val Accuracy')\n",
    "    y.append(item[0].history['val_accuracy'][-1])\n",
    "\n",
    "fig.add_trace(go.Bar(x=x, y=y))\n",
    "\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('GRU2_Barplot_Val_Acc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>LSTM-1 Grid Search Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to be used during our Grid Search. The patience values were\n",
    "# decided based on the Vanilla 1-Layer LSTM trained\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=8, min_lr=0.00005, verbose=1)\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=16)\n",
    "timelog = timelogCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a 1-Layer LSTM model with tuneable hyper-parameters\n",
    "# Returns a compiled model.\n",
    "\n",
    "def create_LSTM1(em_dims, units):\n",
    "    LSTM1_model = keras.Sequential([\n",
    "        keras.layers.Embedding(len(word_index)+1, em_dims, input_length=520),\n",
    "        keras.layers.LSTM(units),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    LSTM1_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hyper_params['LR']),\n",
    "                     loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return LSTM1_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for grid search\n",
    "\n",
    "em_dims = [128, 256]\n",
    "unit1 = [100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform grid search and store the results in a dictionary for use later\n",
    "\n",
    "LSTM1_history_dict = {}\n",
    "for em_dim in em_dims:\n",
    "    for u1 in unit1:\n",
    "        model = create_LSTM1(em_dim, u1)\n",
    "        history = model.fit(training_padded, train_labels, batch_size = hyper_params['BS'],\n",
    "                                epochs=250, validation_data=(testing_padded, test_labels),\n",
    "                               callbacks=[reduce_lr, earlystop, timelog])\n",
    "        LSTM1_history_dict[f'LSTM1_history_{em_dim}_{u1}'] = history, timelog.timelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history and timelog of each model from the dictionary created in the cell above into a csv file\n",
    "\n",
    "for title, item in LSTM1_history_dict.items():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(item[0].history)\n",
    "    time_df = pd.DataFrame(item[1])\n",
    "\n",
    "    # save to csv:\n",
    "    hist_csv_file = 'History_' + str(title) + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    time_csv_file = 'Time_' + str(title) + '.csv'\n",
    "    with open(time_csv_file, mode='w') as f:\n",
    "        time_df.to_csv(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss figure for the history of each model trained during grid search. Save it as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in LSTM1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['loss'], name=str(key)+'Training Loss'))\n",
    "for key, item in LSTM1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_loss'], name=str(key)+'Val Loss'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('LSTM1_Gridsearch_Loss.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save accuracy figure for the history of each model trained during grid search. Save as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in LSTM1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['accuracy'], name=str(key)+'Training Accuracy'))\n",
    "for key, item in LSTM1_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_accuracy'], name=str(key)+'Val Accuracy'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('LSTM1_Gridsearch_Accuracy.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy of the grid searched models. Validation Accuracy is determined by the \n",
    "# last epoch of training\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key, item in LSTM1_history_dict.items():\n",
    "    x.append(str(key)+'Val Accuracy')\n",
    "    y.append(item[0].history['val_accuracy'][-1])\n",
    "\n",
    "fig.add_trace(go.Bar(x=x, y=y))\n",
    "\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('LSTM1_Barplot_Val_Acc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>LSTM-2 Grid Search Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to be used during our Grid Search. The patience values were\n",
    "# decided based on the Vanilla 2-Layer LSTM trained\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=8, min_lr=0.00005, verbose=1)\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=16)\n",
    "timelog = timelogCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a 2-Layer LSTM model with tuneable hyper-parameters\n",
    "# Returns a compiled model.\n",
    "\n",
    "def create_LSTM2(em_dims, unit1, unit2):\n",
    "    LSTM2_model = keras.Sequential([\n",
    "        keras.layers.Embedding(len(word_index)+1, em_dims, input_length=520),\n",
    "        keras.layers.LSTM(unit1, return_sequences=True),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.LSTM(unit2),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    LSTM2_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
    "                     loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return LSTM2_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for grid search\n",
    "\n",
    "em_dims = [128, 256]\n",
    "unit1 = [100, 200]\n",
    "unit2 = [100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search and store the results in a dictionary for use later\n",
    "\n",
    "LSTM2_history_dict = {}\n",
    "for em_dim in em_dims:\n",
    "    for u1 in unit1:\n",
    "        for u2 in unit2:\n",
    "            model = create_LSTM2(em_dim, u1, u2)\n",
    "            history = model.fit(training_padded, train_labels, batch_size = hyper_params['BS'],epochs=250, validation_data=(testing_padded, test_labels),callbacks=[reduce_lr, earlystop, timelog])\n",
    "            LSTM2_history_dict[f'LSTM1_history_{em_dim}_{u1}_{u2}'] = history, timelog.timelog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history and timelog of each model from the dictionary created in the cell above into a csv file\n",
    "\n",
    "for title, item in LSTM2_history_dict.items():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(item[0].history)\n",
    "    time_df = pd.DataFrame(item[1])\n",
    "\n",
    "    # save to csv:\n",
    "    hist_csv_file = 'History_' + str(title) + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    time_csv_file = 'Time_' + str(title) + '.csv'\n",
    "    with open(time_csv_file, mode='w') as f:\n",
    "        time_df.to_csv(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss figure for the history of each model trained during grid search. Save it as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in LSTM2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['loss'], name=str(key)+'Training Loss'))\n",
    "for key, item in LSTM2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_loss'], name=str(key)+'Val Loss'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('LSTM2_Gridsearch_Loss.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save accuracy figure for the history of each model trained during grid search. Save as a html file\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key, item in LSTM2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['accuracy'], name=str(key)+'Training Accuracy'))\n",
    "for key, item in LSTM2_history_dict.items():\n",
    "    fig.add_trace(go.Scatter(x=item[0].epoch, y=item[0].history['val_accuracy'], name=str(key)+'Val Accuracy'))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('LSTM2_Gridsearch_Accuracy.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy of the grid searched models. Validation Accuracy is determined by the \n",
    "# last epoch of training\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key, item in LSTM2_history_dict.items():\n",
    "    x.append(str(key)+'Val Accuracy')\n",
    "    y.append(item[0].history['val_accuracy'][-1])\n",
    "\n",
    "fig.add_trace(go.Bar(x=x, y=y))\n",
    "\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('LSTM2_Barplot_Val_Acc.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
